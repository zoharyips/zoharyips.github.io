---
layout: post
title: MySql 笔记框架
categories: Database
keywords: [Database, MySql]
image: images/wallpaper/markdown.png
search: true
qrcode: true
catalogue: true
prism: true
description: 临时的 MySql 整体笔记框架
---

1. 基本使用

0. MySql 整体体系结构

1. 所有 Sql 语法

2. 所有存储引擎介绍

3. 锁

4. 事务机制

5. 存储机制

6. B 树

7. Inno DB

8. SQL 查询优化技巧




为了加速数据访问，InnoDB 会把最热点的表数据和索引索引放在内存中开辟的 Buffer Pool 中，Buffer Pool 中有的数据直接命中返回，没有的数据才从硬盘读取。以最大限度地减少磁盘 IO。

![Buffer Pool 逻辑结构图 -- MySql Doc](/images/posts/mysql/innodb-buffer-pool-list.png)

* Buffer Pool 存储数据**以页为单位**，与 InnoDB 的磁盘存储基本单位一致，默认是 16K。以页为单位暂存数据的做法是源于**局部性原理**，这也是众多计算机优化技术的基石。

* 根据时间局部性原理，最近使用过的页近期内很有可能会再次使用。根据空间局部性原理，近期需要用到的页很可能在逻辑空间上与当前用到的页是临近的。因此 Buffer Pool **依据 LRU （{最近最少使用}(Least Recent Used)）算法缓存最近使用的数据，同时会以预读的方式缓存附近的几页数据**。

* 单链表非常适合作为 LRU 算法的实现数据结构，因此以**页为元素的单链表是 Buffer Pool 的存储数据结构**。

* 预读机制理所当然带来了**预读失败**的问题，即预读到的数据在未来并没有使用到。解决这个问题的思路是**预读失败的数据仅快地淘汰出去**。解决方案是**通过分代的机制，将 Buffer Pool 分为 New SubList 和 Old SubList 两部分，将新读取的页置于 Old SubList 的头部，Old SubList 的任何数据在再次被读取到的时候置于 New SubList 的头部**，这样预读失败的数据就会更快地从 Old SubList 中淘汰出去。

* 由预读失败我们可以想到另一个潜在的问题：预读失败的数据我们的读取次数是零次，但逻辑上它和读取一次的数据是相同的，我们希望他们能尽快地淘汰出去，但是在一次全表扫面或索引扫描的时候，同一个数据页可能会在这一小段时间内被访问数次，但在未来它却不再被访问到，此时由于它已经被置于 New SubList 头部，同时已经将原有的热点数据淘汰出去了，民间将此称之为**缓冲池污染**问题。这个问题也可能表现为预读的数据正好后续会被使用一两次，而污染了缓冲池热点数据。

    与预读失败一样，我们解决的思路仍旧是将这些数据拒之于 New SubList 门外，因此我们要做的是**提高 New SubList 的准入门槛**。提高准入门槛即让数据页在 Old SubList 中多呆一会，度量方式有两种：次数和时间。InnoDB 采用时间的度量方式，大概是因为在一次 Query 中对于相同数据页的访问次数差异较大，但是 Query 的执行时间平均差异比较小。因此实际 InnoDB 的解决方案是{时间窗口}(Time Window)**机制**：对于 Old SubList 中的数据页，当且仅当在停留了指定时间后还能被重新访问到，才能转移到 New SubList 中，默认窗口大小是 1s。

> 这两个问题出现的原因都是：热点数据容易被驱逐。解决方案的目的都是：保护热点数据。解决方法都是：提高热点数据区的准入门槛。

同时，对于 Buffer Pool 中热点数据的修改， InnoDB 将直接修改 Buffer Pool 中的数据，并将该操作写入 redo log 中，这样能最大限度地加速数据的修改。下一次读取该数据页时，直接返回 Buffer Pool 中修改好的数据。直到该数据页被 LRU 算法淘汰时写入磁盘中，若写入前系统崩溃，则在重启系统之后，使用 redo log 进行恢复。
    
#### Change Buffer

Buffer Pool 加速了读操作，对数据的操作无非读写两种，因此我们同样希望有一种缓冲机制来加速写操作，InnoDB 在 Buffer Pool 中设置了 Change Buffer 来加速部分有关写的操作。

![Change Buffer 逻辑结构图 -- MySql Doc](/images/posts/mysql/innodb-change-buffer.png)

**Change Buffer 是 Buffer Pool 的一部分，用于缓冲二级索引的写入操作，其物理结构为一棵称为 ibuf 的 B 树，其叶子节点同样以页为单位，其默认大小为 16k**。Change Buffer 的生效条件如下：

1. InnoDB 引擎启用 `innodb_change_buffering`

2. 对二级索引索引树的叶子节点的修改，数据页修改无法缓冲，即聚簇索引修改无法缓冲。

3. 该索引页不存在于 Buffer Pool 中，必须进行磁盘 io 才能获取到。

4. 对于唯一二级索引，仅有删除操作可以缓冲。

5. 当前修改表没有执行 `flush` 操作。

**Change Buffer 解决的问题是二级索引在进行写操作时，由于索引数据的不连续性导致频繁的磁盘 IO 而消耗大量的时间与性能。解决问题的方式是将零散的索引页修改进行缓冲，缓冲到一定量或等到系统较为空闲时进行 `ibuf merge` 操作将修改合并到数据页中**。

Change Buffer 数据合并的时机为：

* 用户选择该二级索引进行查询。

* 尝试缓存插入操作时，若预估 page 空间不足可能导致二级索引页分裂，将定位到 ibuf btree 正在尝试缓存的页位置，以异步的方式从该位置起 merge 8 个 page，该数量由参数 `IBUF_MERGE_AREA` 决定

* 本次缓存操作，发现 ibuf btree 会页分裂：

    * 未超出大小 Change Buffer 大小限制，不理会。

    * 超出限制，大小超出 `IBUF_CONTRACT_ON_INSERT_SYNC = 5` 这么多个页，则执行一次同步 merge，位置随机。

    * 超出限制，未超出 `IBUF_CONTRACT_ON_INSERT_SYNC = 5` 这么多个页，则执行一次异步 merge，位置随机。

* Change Buffer 已使用大小超出限制时，且超出 `IBUF_CONTRACT_DO_NOT_INSERT = 10` 个以上时，启用同步 merge，随机 merge 页面，最多 merge 8 个页面，同时放弃此次缓冲。

* master 线程发起 merge 命令。

* 对该表进行 flush 操作。

MySql 5.5 前，写缓冲仅支持 insert 操作，因此当时命名为 Insert Buffer，MySql 代码、参数中随处可见的 `ibuf` 便源于此。而后支持 delete-mark 与 delete 操作（InnoDB 的更新以删除 + 插入实现），便改成 Change Buffer。


#### Adactive Hash Index

InnoDB 使用的索引数据结构是 B+ 树，数的高度一般处于 3 到 4 层之间，较小的高度使得查询数据页时磁盘 IO 的次数大大降低，但数据放置于叶节点处使得每次查询数据都得从树根节点遍历到页节点，这个搜索过程同样耗费时间。同时对于二级索引而言，二级索引仅仅是定位数据的主键，依旧需要根据主键再次去聚簇索引定位数据页的位置，整体链路稍微有点长。对于热点数据，我们希望能够一次查询便定位到具体数据，而非每次都要经过 3 次甚至以上的查询，为此 InnoDB 使用{自适应哈希索引(AHI)}(Adactive Hash Index)进行优化。

![Adactive Hash Index](/images/posts/mysql/innodb-adative-hash-index.png)

**AHI 所作用的对象是索引树上的叶节点，因此它是一个建立在索引之上的索引**。其 Key 根据索引中的部分或者全部列数计算而出，在查询数据时，InnoDB 会根据查询条件分析是否能使用 AHI，若判断可以使用 AHI 并命中查询，则直接获得记录指针，一次查询便可获得索引数据页。

AHI AHI 的建立条件与查询条件都非常苛刻和复杂，这一切都是为了做到更好的{自适应}(self-tuning)。其占用空间大小为 Buffer Pool 的 1/64，在 MySql 5.7 版本之后 AHI 支持分区，以减少之前出现的全局 AHI 锁竞争的问题，默认分为 8 个分区。

1. 命中 AHI 所建立的目标索引。

2. 非空间索引，且无需分配外部存储页。

3. `btr_search_latch` 没有加写锁，每一个 AHI 分区都依靠 `btr_search_latch` 读写锁进行保护。

4. InnoDB 开启 AHI

5. `last_hash_succ == TRUE`，即上一次使用 AHI 搜索成功。

6. 查询条件为等值查询，即使用 `=` 或 `<=>` 操作符进行查询。

7. 查询条件覆盖构建 AHI 时所使用的前缀索引列，根据查询列和查询值计算哈希值。

8. 查询 AHI 并判断是否命中，命中返回记录指针，命中失败将 `last_hash_succ` 置于 false，在下次查询信息分析前无法使用该 AHI。

#### Log Buffer

InnoDB 使用 Log Buffer 来缓冲日志文件的写入操作。由于日志文件顺序写的特点，加之使用 Log Buffer 在内存中进行日志写入使得日志写入的性能极高。

InnoDB 使用包括 redo log 和 undo log 等等的日志文件。redo log 的思想是将分散、随机、IO 消耗高的写入操作记录起来，转化为批量、顺序的写入操作，以大大减小磁盘 IO。undo log 主要用于记录记录变更的历史版本，以支持事务回滚之后的数据恢复功能和 InnoDB 的{多并发版本控制}(Multiple Version Concurrency Control)功能。同样，为保证 undo log 的一致性和快速写入，undo log 的修改同样需要 redo log 的支持。而这些日志文件都保存在磁盘中。面对频繁、分散的数据修改，对于日志文件的写入反倒会增加磁盘 IO 使得日志文件存在的作用适得其反。

因此，**Log Buffer 将日志的分散写入操作放在了内存中，通过定期批量写入磁盘的机制提高日志写入和减少磁盘 IO。这种延迟写入，转分散操作为批量操作的优化带来的后果就是增加数据丢失的风险**。

在 Log Buffer 
